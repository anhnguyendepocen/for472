[
["spatial-data-visualization-and-analysis.html", "Chapter 9 Spatial Data Visualization and Analysis 9.1 Overview 9.2 Motivating Data 9.3 Reading Spatial Data into R 9.4 Coordinate Reference Systems 9.5 Illustration using ggmap 9.6 Illustration using leaflet 9.7 Subsetting Spatial Data 9.8 Where to go from here", " Chapter 9 Spatial Data Visualization and Analysis 9.1 Overview Recall, a data structure is a format for organizing and storing data. The structure is designed so that data can be accessed and worked with in specific ways. Statistical software and programming languages have methods (or functions) designed to operate on different kinds of data structures. This chapter focuses on spatial data structures and some of the R functions that work with these data. Spatial data comprise values associated with locations, such as temperature data at a given latitude, longitude, and perhaps elevation. Spatial data are typically organized into vector or raster data types. (See Figure 9.1). Vector data represent features such as discrete points, lines, and polygons. Raster data represent surfaces as a rectangular matrix of square cells or pixels. FIGURE 9.1: Raster/Vector Comparison Wegmann (2010) Whether or not you use vector or raster data depends on the type of problem, the type of maps you need, and the data source. Each data structure has strengths and weaknesses in terms of functionality and representation. As you gain more experience working with spatial data, you will be able to determine which structure to use for a particular application. There is a large set of R packages available for working with spatial (and space-time) data. These packages are described in the Cran Task View: Analysis of Spatial Data. The CRAN task view attempts to organize the various packages into categories, such as Handling spatial data, Reading and writing spatial data, Visualization, and Disease mapping and areal data analysis, so users can quickly identify package options given their project needs. Exploring the extent of the excellent spatial data tools available in R is beyond the scope of this book. Rather, we would point you to subject texts like Applied Spatial Data Analysis with R by Bivand, Pebesma, and Gomez-Rubio (2013) (available for free via the MSU library system), and numerous online tutorials on pretty much any aspect of spatial data analysis with R. These tools make R a full-blown Geographic Information System (GIS) capable of spatial data manipulation and analysis on par with commercial GIS systems such as ESRI’s ArcGIS. 9.1.1 Some Spatial Data Packages This chapter will focus on a few R packages for manipulating and visualizing spatial data. Specifically we will touch on the following packages sp: spatial data structures and methods rgdal: interface to the C/C++ spatial data Geospatial Data Abstraction Library ggmap: extends ggplot2 language to handle spatial data leaflet: generates dynamic online maps 9.2 Motivating Data We motivate the topics introduced in this chapter using some forestry data from the Penobscot Experimental Forest (PEF) located in Maine (which you’ve previously seen throughout the course). The PEF is a long-term experimental forest that is used to understand the effects of silviculture (i.e., science of tending trees) treatments on forest growth and composition. The PEF is divided into non-overlapping management units that receive different harvesting treatments. Within each management unit is a series of observation point locations (called forest inventory plots) where forest variables have been measured. Ultimately, we want to summarize the inventory plots measurements by management unit and map the results. 9.3 Reading Spatial Data into R Spatial data come in a variety of file formats. Examples of popular vector file formats for points, lines, and polygons, include ESRI’s shapefile and open standard GeoJSON. Common raster file formats include GeoTIFF and netCDF1. The rgdal function readOGR will read a large variety of vector data file formats (there is also a writeOGR() for writing vector data files). Raster data file formats can be read using the rgdal function readGDAL (yup, also a writeGDAL()) or read functions in the raster package. All of these functions automatically cast the data into an appropriate R spatial data object (i.e., data structure), which are defined in the sp or raster packages. Table 9.1 provides an abbreviated list of these R spatial objects2. The Without attributes column gives the sp package’s spatial data object classes for points, lines, polygons, and raster pixels that do not have data associated with the spatial objects (i.e., without attributes in GIS speak). DataFrame is appended to the object class name once data, in the form of variables, are added to the spatial object. TABLE 9.1: An abbreviated list of sp and raster data objects and associated classes for the fundamental spatial data types Without Attributes With Attributes Polygons SpatialPolygons SpatialPolygonsDataFrame Points SpatialPoints SpatialPointsDataFrame Lines SpatialLines SpatialLinesDataFrame Raster SpatialGrid SpatialGridDataFrame Raster SpatialPixels SpatialPixelsDataFrame Raster RasterLayer Raster RasterBrick Raster RasterStack You can create your own spatial data objects in R. Below, for example, we create a SpatialPoints object consisting of four points. Then add some data to the points to make it a SpatialPointsDataFrame. library(sp) library(dplyr) x &lt;- c(3,2,5,6) y &lt;- c(2,5,6,7) coords &lt;- cbind(x, y) sp.pts &lt;- SpatialPoints(coords) class(sp.pts) ## [1] &quot;SpatialPoints&quot; ## attr(,&quot;package&quot;) ## [1] &quot;sp&quot; some.data &lt;- data.frame(var.1 = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;), var.2 = 1:4) sp.pts.df &lt;- SpatialPointsDataFrame(sp.pts, some.data) class(sp.pts.df) ## [1] &quot;SpatialPointsDataFrame&quot; ## attr(,&quot;package&quot;) ## [1] &quot;sp&quot; If, for example, you already have a data frame that includes the spatial coordinate columns and other variables, then you can promote it to a SpatialPointsDataFrame by indicating which columns contain point coordinates. You can extract or access the data frame associated with the spatial object using @data. You can also access individual variables directly from the spatial object using $ or by name or column number to the right of the comma in [,] (analogues to accessing variables in a data frame). df &lt;- data.frame(x = c(3,2,5,6), y=c(2,5,6,7), var.1 = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;), var.2 = 1:4) class(df) ## [1] &quot;data.frame&quot; #promote to a SpatialPointsDataFrame coordinates(df) &lt;- ~x+y class(df) ## [1] &quot;SpatialPointsDataFrame&quot; ## attr(,&quot;package&quot;) ## [1] &quot;sp&quot; #access entire data frame df@data ## var.1 var.2 ## 1 a 1 ## 2 b 2 ## 3 c 3 ## 4 d 4 class(df@data) ## [1] &quot;data.frame&quot; #access columns directly df$var.1 ## [1] a b c d ## Levels: a b c d df[,c(&quot;var.1&quot;,&quot;var.2&quot;)] ## coordinates var.1 var.2 ## 1 (3, 2) a 1 ## 2 (2, 5) b 2 ## 3 (5, 6) c 3 ## 4 (6, 7) d 4 df[,2] ## coordinates var.2 ## 1 (3, 2) 1 ## 2 (2, 5) 2 ## 3 (5, 6) 3 ## 4 (6, 7) 4 #get the bounding box bbox(df) ## min max ## x 2 6 ## y 2 7 Here, the data frame df is promoted to a SpatialPointsDataFrame by indicating the column names that hold the longitude and latitude (i.e., x and y respectively) using the coordinates function. Here too, the @data is used to retrieve the data frame associated with the points. We also illustrate how variables can be accessed directly from the spatial object. The bbox function is used to return the bounding box that is defined by the spatial extent of the point coordinates. The other spatial objects noted in Table 9.1 can be created, and their data accessed, in a similar way3. More than often we find ourselves reading existing spatial data files into R. The code below uses the downloader package to download all of the PEF data we’ll use in this chapter. The data are compressed in a single zip file, which is then extracted into the working directory using the unzip function. A look into the PEF directory using list.files shows nine files4. Those named MU-bounds.* comprise the shapefile that holds the PEF’s management unit boundaries in the form of polygons. Like other spatial data file formats, shapefiles are made up of several different files (with different file extensions) that are linked together to form a spatial data object. The plots.csv file holds the spatial coordinates and other information about the PEF’s forest inventory plots. The roads.* shapefile holds roads and trails in and around the PEF. library(downloader) download(&quot;http://blue.for.msu.edu/FOR875/data/PEF.zip&quot;, destfile=&quot;./PEF.zip&quot;, mode=&quot;wb&quot;) unzip(&quot;PEF.zip&quot;, exdir = &quot;.&quot;) list.files(&quot;PEF&quot;) ## [1] &quot;MU-bounds.dbf&quot; &quot;MU-bounds.prj&quot; &quot;MU-bounds.qpj&quot; &quot;MU-bounds.shp&quot; ## [5] &quot;MU-bounds.shx&quot; &quot;plots.csv&quot; &quot;plots.dbf&quot; &quot;plots.prj&quot; ## [9] &quot;plots.qpj&quot; &quot;plots.shp&quot; &quot;plots.shx&quot; &quot;roads.dbf&quot; ## [13] &quot;roads.prj&quot; &quot;roads.shp&quot; &quot;roads.shx&quot; Next we read the MU-bounds shapefile into R using readOGR()5 and explore the resulting mu object. Notice that when we read a shapefile into R, we do not include a file extension with the shapefile name because a shapefile is always composed of multiple files. library(rgdal) ## rgdal: version: 1.3-6, (SVN revision 773) ## Geospatial Data Abstraction Library extensions to R successfully loaded ## Loaded GDAL runtime: GDAL 2.2.3, released 2017/11/20 ## Path to GDAL shared files: /usr/share/gdal/2.2 ## GDAL binary built with GEOS: TRUE ## Loaded PROJ.4 runtime: Rel. 4.9.3, 15 August 2016, [PJ_VERSION: 493] ## Path to PROJ.4 shared files: (autodetected) ## Linking to sp version: 1.3-1 mu &lt;- readOGR(&quot;PEF&quot;, &quot;MU-bounds&quot;) ## OGR data source with driver: ESRI Shapefile ## Source: &quot;/home/jeffdoser/Dropbox/teaching/for472/text/book/PEF&quot;, layer: &quot;MU-bounds&quot; ## with 40 features ## It has 1 fields When called, the readOGR function provides a bit of information about the object being read in. Here, we see that it read the MU-bounds shapefile from PEF directory and the shapefile had 40 features (i.e., polygons) and 1 field (i.e., field is synonymous with column or variable in the data frame). You can think of the resulting mu object as a data frame where each row corresponds to a polygon and each column holds information about the polygon6. More specifically, the mu object is a SpatialPolygonsDataFrame. class(mu) ## [1] &quot;SpatialPolygonsDataFrame&quot; ## attr(,&quot;package&quot;) ## [1] &quot;sp&quot; As illustrated using the made-up point data in the example above, you can access the data frame associated with the polygons using @data. class(mu@data) ## [1] &quot;data.frame&quot; dim(mu@data) ## [1] 40 1 head(mu@data) ## mu_id ## 0 C15 ## 1 C17 ## 2 C16 ## 3 C27 ## 4 U18 ## 5 U31 Above, a call to class() confirms we have accessed the data frame, dim() shows there are 40 rows (one row for each polygon) and one column, and head() shows the first six values of the column named mu_id. The mu_id values are unique identifiers for each management unit polygon across the PEF. 9.4 Coordinate Reference Systems One of the more challenging aspects of working with spatial data is getting used to the idea of a coordinate reference system. A coordinate reference system (CRS) is a system that uses one or more numbers, or coordinates, to uniquely determine the position of a point or other geometric element (e.g., line, polygon, raster). For spatial data, there are two common coordinate systems: Spherical coordinate system, such as latitude-longitude, often referred to as a geographic coordinate system. Projected coordinate system based on a map projection, which is a systematic transformation of the latitudes and longitudes that aims to minimize distortion occurring from projecting maps of the earth’s spherical surface onto a two-dimensional Cartesian coordinate plane. Projected coordinate systems are sometimes referred to as map projections. There are numerous map projections7. One of the more frustrating parts of working with spatial data is that it seems like each data source you find offers its data in a different map projection and hence you spend a great deal of time reprojecting (i.e., transforming from one CRS to another) data into a common CRS such that they overlay correctly. Reprojecting is accomplished using the sp package’s spTransform function as demonstrated in Section 9.5. In R, a spatial object’s CRS is accessed via the sp package proj4string function. The code below shows the current projection of mu. proj4string(mu) ## [1] &quot;+proj=utm +zone=19 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0&quot; The cryptic looking string returned by proj4string() is a set of directives understood by the proj.4 C library, which is part of sp, and used to map geographic longitude and latitude coordinates into the projected Cartesian coordinates. This CRS tells us the mu object is in Universal Transverse Mercator (UTM) zone 19 coordinate system.8 9.5 Illustration using ggmap Let’s begin by making a map of PEF management unit boundaries over top of a satellite image using the ggmap package. Given an address, location, or bounding box, the ggmap package’s get_map function will query Google Maps, OpenStreetMap, Stamen Maps, or Naver Map servers for a user-specified map type. The get_map function requires the location or bounding box coordinates be in a geographic coordinate system (i.e., latitude-longitude). This means we need to reproject mu from UTM zone 19 to latitude-longitude geographic coordinates, which is defined by the '&quot;proj=longlat +datum=WGS84&quot;' proj.4 string. As seen below, the first argument in spTransform function is the spatial object to reproject and the second argument is a CRS object created by passing a proj.4 string into the CRS function. mu &lt;- spTransform(mu, CRS(&quot;+proj=longlat +datum=WGS84&quot;)) proj4string(mu) ## [1] &quot;+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0&quot; Unfortunately, we cannot just feed the SpatialPolygonsDataFrame mu into ggplot (perhaps some day soon this will possible). Rather, we need to first convert the SpatialPolygonsDataFrame into a specially formatted data frame using the fortify function that is part of the ggplot2 package9. The fortify function will also need a unique identifier for each polygon specified using the region argument, which for mu is the mu_id. library(ggmap) ## Loading required package: ggplot2 ## Google Maps API Terms of Service: http://developers.google.com/maps/terms. ## Please cite ggmap if you use it: see citation(&quot;ggmap&quot;) for details. mu.f &lt;- fortify(mu, region=&quot;mu_id&quot;) head(mu.f) ## long lat order hole piece id group ## 1 -68.62065 44.85504 1 FALSE 1 C12 C12.1 ## 2 -68.61809 44.85817 2 FALSE 1 C12 C12.1 ## 3 -68.61810 44.85813 3 FALSE 1 C12 C12.1 ## 4 -68.61812 44.85802 4 FALSE 1 C12 C12.1 ## 5 -68.61811 44.85797 5 FALSE 1 C12 C12.1 ## 6 -68.61812 44.85791 6 FALSE 1 C12 C12.1 Notice the id column in the fortified version of mu holds each polygon’s mu_id value (this will be important later when we link data to the polygons). Next, we query the satellite imagery used to underlay the management units (we’ll generally refer to this underlying map as the basemap). As of October 2018, Google now requires you to set up a Google API account in order to run the following maps. This is free, but it does require a credit card to obtain the API Key that is required to make the ggmap package work. Here I provide you with an API key for a project I created for this class that should allow you to run the following function if you desire. If you are interested in obtaining your own API key, see the page here for learning about how to use Google maps web services. register_google(key = &quot;AIzaSyBPAwSY5x8vQqlnG-QwiCAWQW12U3CTLZY&quot;) mu.bbox &lt;- bbox(mu) basemap &lt;- get_map(location=mu.bbox, zoom = 14, maptype=&quot;satellite&quot;) ggmap(basemap) + geom_polygon(data=mu.f, aes(x = long, y = lat, group=group), fill=NA, size=0.2, color=&quot;orange&quot;) Looks pretty good! Take a look at the get_map function manual page and try different options for maptype (e.g., maptype=&quot;terrain&quot;). Next we’ll add the forest inventory plots to the map. Begin by reading in the PEF forest inventory plot data held in “plots.csv”. Recall, foresters have measured forest variables at a set of locations (i.e., inventory plots) within each management unit. The following statement reads these data and displays the resulting data frame structure. plots &lt;- read.csv(&quot;PEF/plots.csv&quot;, stringsAsFactors=FALSE) str(plots) ## &#39;data.frame&#39;: 451 obs. of 8 variables: ## $ mu_id : chr &quot;U10&quot; &quot;U10&quot; &quot;U10&quot; &quot;U10&quot; ... ## $ plot : int 11 13 21 22 23 24 31 32 33 34 ... ## $ easting : num 529699 529777 529774 529814 529850 ... ## $ northing : num 4966333 4966471 4966265 4966336 4966402 ... ## $ biomass_mg_ha : num 96.3 115.7 121.6 72 122.3 ... ## $ stems_ha : int 5453 2629 3385 7742 7980 10047 5039 5831 2505 7325 ... ## $ diameter_cm : num 4.8 6.9 6.1 3.1 4.7 1.6 4.1 5.2 5.7 3.3 ... ## $ basal_area_m2_ha: num 22 23.2 23 16.1 29.2 19.1 14.1 27.4 21.6 15 ... In plots each row is a forest inventory plot and columns are: mu_id identifies the management unit within which the plot is located plot unique plot number within the management unit easting longitude coordinate in UTM zone 19 northing latitude coordinate in UTM zone 19 biomass_mg_ha tree biomass in metric ton (per hectare basis) stocking_stems_ha number of tree (per hectare basis) diameter_cm average tree diameter measured 130 cm up the tree trunk basal_area_m2_ha total cross-sectional area at 130 cm up the tree trunk (per hectare basis) There is nothing inherently spatial about this data structure—it is simply a data frame. We make plots into a spatial object by identifying which columns hold the coordinates. This is done below using the coordinates function, which promotes the plots data frame to a SpatialPointsDataFrame. coordinates(plots) &lt;- ~easting+northing class(plots) ## [1] &quot;SpatialPointsDataFrame&quot; ## attr(,&quot;package&quot;) ## [1] &quot;sp&quot; Although plots is now a SpatialPointsDataFrame, it does not know to which CRS the coordinates belong; hence, the NA when proj4string(plots) is called below. As noted in the plots file description above, easting and northing are in UTM zone 19. This CRS is set using the second call to proj4string below. proj4string(plots) ## [1] NA proj4string(plots) &lt;- CRS(&quot;+proj=utm +zone=19 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0&quot;) Now let’s reproject plots to share a common CRS with mu plots &lt;- spTransform(plots, CRS(&quot;+proj=longlat +datum=WGS84&quot;)) Note, because mu is already in the projection we want for plots, we could have replaced the second argument in the spTransform call above with proj4string(mu) and saved some typing. We’re now ready to add the forest inventory plots to the existing basemap with management units. Specifically, let’s map the biomass_mg_ha variable to show changes in biomass across the forest. No need to fortify plots, ggplot is happy to take geom_point’s data argument as a data frame (although we do need to convert plots from a SpatialPointsDataFrame to a data frame using the as.data.frame function). Check out the scale_color_gradient function in your favorite ggplot2 reference to understand how the color scale is set. ggmap(basemap) + geom_polygon(data=mu.f, aes(x = long, y = lat, group=group), fill=NA, size=0.2, color=&quot;orange&quot;) + geom_point(data=as.data.frame(plots), aes(x = easting, y = northing, color=biomass_mg_ha)) + scale_color_gradient(low=&quot;white&quot;, high=&quot;darkblue&quot;) + labs(color = &quot;Biomass (mg/ha)&quot;) There is something subtle and easy to miss in the code above. Notice the aes function arguments in geom_points take geographic longitude and latitude, x and y respectively, from the points data frame (but recall easting and northing were in UTM zone 19). This works because we applied spTransform to reproject the points SpatialPointsDataFrame to geographic coordinates. sp then replaces the values in easting and northing columns with the reprojected coordinate values when converting a SpatialPointsDataFrame to a data frame via as.data.frame(). Foresters use the inventory plot measurements to estimate forest variables within management units, e.g., the average or total management unit biomass. Next we’ll make a plot with management unit polygons colored by average biomass_mg_ha. mu.bio &lt;- plots@data %&gt;% group_by(mu_id) %&gt;% summarize(biomass_mu = mean(biomass_mg_ha)) print(mu.bio) ## # A tibble: 33 x 2 ## mu_id biomass_mu ## &lt;chr&gt; &lt;dbl&gt; ## 1 C12 124. ## 2 C15 49.9 ## 3 C16 128. ## 4 C17 112. ## 5 C20 121. ## 6 C21 134. ## 7 C22 65.2 ## 8 C23A 108. ## 9 C23B 153. ## 10 C24 126. ## # ... with 23 more rows Recall from Section 6.5 this one-liner can be read as “get the data frame from plots’s SpatialPointsDataFrame then group by management unit then make a new variable called biomass_mu that is the average of biomass_mg_ha and assign it to the mu.bio tibble.” The management unit specific biomass_mu can now be joined to the mu polygons using the common mu_id value. Remember when we created the fortified version of mu called mu.f? The fortify function region argument was mu_id which is the id variable in the resulting mu.f. This id variable in mu.f can be linked to the mu_id variable in mu.bio using dplyr’s left_join function as illustrated below. head(mu.f, n=2) ## long lat order hole piece id group ## 1 -68.62065 44.85504 1 FALSE 1 C12 C12.1 ## 2 -68.61809 44.85817 2 FALSE 1 C12 C12.1 mu.f &lt;- left_join(mu.f, mu.bio, by = c(&#39;id&#39; = &#39;mu_id&#39;)) head(mu.f, n=2) ## long lat order hole piece id group biomass_mu ## 1 -68.62065 44.85504 1 FALSE 1 C12 C12.1 123.7338 ## 2 -68.61809 44.85817 2 FALSE 1 C12 C12.1 123.7338 The calls to head() show the first few rows of mu.f pre- and post-join. After the join, mu.f includes biomass_mu, which is used used below for geom_polygon’s fill argument to color the polygons accordingly. ggmap(basemap) + geom_polygon(data=mu.f, aes(x = long, y = lat, group=group, fill=biomass_mu), size=0.2, color=&quot;orange&quot;) + scale_fill_gradient(low=&quot;white&quot;, high=&quot;darkblue&quot;, na.value=&quot;transparent&quot;) + labs(fill=&quot;Biomass (mg/ha)&quot;) Let’s add the roads and some more descriptive labels as a finishing touch. The roads data include a variable called type that identifies the road type. To color roads by type in the map, we need to join the roads data frame with the fortified roads roads.f using the common variable id as a road segment specific identifier. Then geom_path’s color argument gets this type variable as a factor to create road-specific color. The default coloring of the roads blends in too much with the polygon colors, so we manually set the road colors using the scale_color_brewer function. The palette argument in this function accepts a set of key words, e.g., &quot;Dark2&quot;, that specify sets of diverging colors chosen to make map object difference optimally distinct (see, the manual page for scale_color_brewer, http://colorbrewer2.org, and blog here.)10 roads &lt;- readOGR(&quot;PEF&quot;, &quot;roads&quot;) ## OGR data source with driver: ESRI Shapefile ## Source: &quot;/home/jeffdoser/Dropbox/teaching/for472/text/book/PEF&quot;, layer: &quot;roads&quot; ## with 33 features ## It has 2 fields roads &lt;- spTransform(roads, proj4string(mu)) roads.f &lt;- fortify(roads, region=&quot;id&quot;) roads.f &lt;- left_join(roads.f, roads@data, by = c(&#39;id&#39; = &#39;id&#39;)) ## Warning: Column `id` joining character vector and factor, coercing into ## character vector ggmap(basemap) + geom_polygon(data=mu.f, aes(x = long, y = lat, group=group, fill=biomass_mu), size=0.2, color=&quot;orange&quot;) + geom_path(data=roads.f, aes(x = long, y = lat, group=group, color=factor(type))) + scale_fill_gradient(low=&quot;white&quot;, high=&quot;darkblue&quot;, na.value=&quot;transparent&quot;) + scale_color_brewer(palette=&quot;Dark2&quot;) + labs(fill=&quot;Biomass (mg/ha)&quot;, color=&quot;Road type&quot;, xlab=&quot;Longitude&quot;, ylab=&quot;Latitude&quot;, title=&quot;PEF forest biomass&quot;) ## Warning: Removed 616 rows containing missing values (geom_path). The second, and more cryptic, of the two warnings from this code occurs because some of the roads extend beyond the range of the map axes and are removed (nothing to worry about). 9.6 Illustration using leaflet Leaflet is one of the most popular open-source JavaScript libraries for interactive maps. As noted on the official R leaflet website, it’s used by websites ranging from The New York Times and The Washington Post to GitHub and Flickr, as well as by GIS specialists like OpenStreetMap, Mapbox, and CartoDB. The R leaflet website is an excellent resource to learn leaflet basics, and should serve as a reference to gain a better understanding of the topics we briefly explore below. You create a leaflet map using these basic steps: Create a map by calling leaflet() Add data layers to the map using layer functions such as, addTiles(), addMarkers(), addPolygons(), addCircleMarkers(), addPolylines(), addRasterImage() and other add... functions Repeat step 2 to add more layers to the map Print the map to display it Here’s a brief example. library(leaflet) m &lt;- leaflet() %&gt;% addTiles() %&gt;% # Add default OpenStreetMap map tiles addMarkers(lng=-84.482004, lat=42.727516, popup=&quot;&lt;b&gt;Here I am!&lt;/b&gt;&quot;) # Add a clickable marker m # Print the map There are a couple things to note in the code. First, we use the pipe operator %&gt;% just like in dplyr functions. Second, the popup argument in addMarkers() takes standard HTML and clicking on the marker makes the text popup. Third, the html version of this text provides the full interactive, dynamic map, so we encourage you to read and interact with the html version of this textbook for this section. The PDF document will simply display a static version of this map and will not do justice to how awesome leaflet truly is! As seen in the leaflet() call above, the various add... functions can take longitude (i.e., lng) and latitude (i.e., lat). Alternatively, these functions can extract the necessary spatial information from sp objects, e.g., Table 9.1, when passed to the data argument (which greatly simplifies life compared with map making using ggmap). 9.7 Subsetting Spatial Data You can imagine that we might want to subset spatial objects to map specific points, lines, or polygons that meet some criteria, or perhaps extract values from polygons or raster surfaces at a set of points or geographic extent. These, and similar types, of operations are easy in R (as long as all spatial objects are in a common CRS). Recall from Chapter 5 how handy it is to subset data structures, e.g., vectors and data frames, using the [] operator and logical vectors? Well it’s just as easy to subset spatial objects, thanks to the authors of sp, raster, and other spatial data packages. 9.7.1 Fetching and Cropping Data using raster In order to motivate our exploration of spatial data subsetting and to illustrate some useful functionality of the raster package, let’s download some elevation data for the PEF. The raster package has a rich set of functions for manipulating raster data as well as functions for downloading data from open source repositories. We’ll focus on the package’s getData function, which, given a location in geographic longitude and latitude or location name, will download data from GADM, Shuttle Radar Topography Mission, Global Climate Data, and other sources commonly used in spatial data applications. Let’s download SRTM surface elevation data for the PEF, check the resulting object’s class and CRS, and display it using the raster package’s image function along with the PEF forest inventory plots. library(raster) ## ## Attaching package: &#39;raster&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## select pef.centroid &lt;- as.data.frame(plots) %&gt;% summarize(mu.x = mean(easting), mu.y = mean(northing)) srtm &lt;- getData(&quot;SRTM&quot;, lon = pef.centroid[, 1], lat = pef.centroid[, 2]) ## Error in .SRTM(..., download = download, path = path): file not found srtm &lt;- raster(&quot;srtm_23_04.tif&quot;) proj4string(srtm) &lt;- &quot;+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0&quot; class(srtm) ## [1] &quot;RasterLayer&quot; ## attr(,&quot;package&quot;) ## [1] &quot;raster&quot; proj4string(srtm) ## [1] &quot;+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0&quot; image(srtm) plot(plots, add = TRUE) A few things to notice in the code above. First the getData function needs the longitude lon and latitude lat to identify which SRTM raster tile to return (SRTM data come in large raster tiles that cover the globe). As usual, look at the getData function documentation for a description of the arguments. To estimate the PEF’s centroid coordinate, we averaged the forest inventory plots’ latitude and longitude then assigned the result to pef.centroid. Second, there is currently a bug with downloading SRTM data using the getData() function. All the data are downloaded into your current directory, but the function does not properly load them into R. If you run this line yourself and get an error, continue going through the code we have. In the next line we load the data in ourselves using the call to raster(&quot;srtm_23_04.tiff&quot;). I also manually change the coordinate system using the proj4string function. The srtm object result from our code to get around the bug is a RasterLayer, see Table 9.1. Third, srtm is in a longitude latitude geographic CRS (same as our other PEF data). Finally, the image shows SRTM elevation along the coast of Maine, the PEF plots are those tiny specks of black in the northwest quadrant, and the white region of the image is the Atlantic Ocean. Okay, this is a start, but it would be good to crop the SRTM image to the PEF’s extent. This is done using raster’s crop function. This function can use many different kinds of spatial objects in the second argument to calculate the extent at which to crop the object in the first argument. Here, I set mu as the second argument and save the resulting SRTM subset over the larger tile (the srtm object). srtm &lt;- crop(srtm, mu) image(srtm) plot(mu, add = TRUE) The crop is in effect doing a spatial setting of the raster data. We’ll return to the srtm data and explore different kinds of subsetting in the subsequent sections. 9.7.2 Logical, Index, and Name Subsetting As promised, we can subset spatial objects using the [] operator and a logical, index, or name vector. The key is that sp objects behave like data frames, see Section 5.5. A logical or index vector to the left of the comma in [,] accesses points, lines, polygons, or pixels. Similarly, a logical, index, or name vector to the right of the comma accesses variables. For example, say we want to map forest inventory plots with more than 10,000 stems per hectare, stems_ha (the min() was added below to double check that the subset worked correctly. min(plots$stems_ha) ## [1] 119 plots.10k &lt;- plots[plots$stems_ha &gt; 10000,] min(plots.10k$stems_ha) ## [1] 10008 You can also add new variables to the spatial objects. plots$diameter_in &lt;- plots$diameter_cm/2.54 head(plots) ## mu_id plot biomass_mg_ha stems_ha diameter_cm basal_area_m2_ha ## 1 U10 11 96.35 5453 4.8 22.0 ## 2 U10 13 115.70 2629 6.9 23.2 ## 3 U10 21 121.58 3385 6.1 23.0 ## 4 U10 22 71.97 7742 3.1 16.1 ## 5 U10 23 122.26 7980 4.7 29.2 ## 6 U10 24 85.85 10047 1.6 19.1 ## diameter_in ## 1 1.8897638 ## 2 2.7165354 ## 3 2.4015748 ## 4 1.2204724 ## 5 1.8503937 ## 6 0.6299213 9.7.3 Spatial Subsetting and Overlay A spatial overlay retrieves the indexes or variables from object \\(A\\) using the location of object \\(B\\). With some spatial objects this operation can be done using the [] operator. For example, say we want to select and map all management units in mu, i.e., \\(A\\), that contain plots with more than 10,000 stems per ha, i.e., \\(B\\). mu.10k &lt;- mu[plots.10k,]## A[B,] mu.10k.f &lt;- fortify(mu.10k, region=&quot;mu_id&quot;) ggmap(basemap) + geom_polygon(data=mu.10k.f, aes(x = long, y = lat, group=group), fill=&quot;transparent&quot;, size=0.2, color=&quot;orange&quot;) + geom_point(data=as.data.frame(plots.10k), aes(x = easting, y = northing), color=&quot;white&quot;) More generally, however, the over function offers consistent overlay operations for sp objects and can return either indexes or variables from object \\(A\\) given locations from object \\(B\\), i.e., over(B, A) or, equivalently, B%over%A. The code below duplicates the result from the preceding example using over. mu.10k &lt;- mu[mu$mu_id %in% unique(over(plots.10k, mu)$mu_id),] Yes, this requires more code but over provides a more flexible and general purpose function for overlays on the variety of sp objects. Let’s unpack this one-liner into its five steps. i &lt;- over(plots.10k, mu) ii &lt;- i$mu_id iii &lt;- unique(ii) iv &lt;- mu$mu_id %in% iii v &lt;- mu[iv,] The over function returns variables for mu’s polygons that coincide with the 85 points in plots.10k. No points fall outside the polygons and the polygons do not overlap, so \\(i\\) should be a data frame with 85 rows. If polygons did overlap and a point fell within the overlap region, then variables for the coinciding polygons are returned. Select the unique mu identifier mu_id (this step is actually not necessary here because mu only has one variable). Because some management units contain multiple plots there will be repeat values of mu_id in ii, so apply the unique function to get rid of duplicates. Use the %in% operator to create a logical vector that identifies which polygons should be in the final map. Subset mu using the logical vector created in \\(iv\\). Now let’s do something similar using the srtm elevation raster. Say we want to map elevation along trails, winter roads, and gravel roads across the PEF. We could subset srtm using the roads SpatialLinesDataFrame; however, mapping the resulting pixel values along the road segments using ggmap requires a bit more massaging. So, to simplify things for this example, roads is first coerced into a SpatialPointsDataFrame called roads.pts that is used to extract spatially coinciding srtm pixel values which themselves are coerced from raster’s RasterLayer to sp’s SpatialPixelsDataFrame called srtm.sp so that we can use the over function. We also choose a different basemap just for fun. hikes &lt;- roads[roads$type %in% c(&quot;Trail&quot;, &quot;Winter&quot;, &quot;Gravel&quot;),] hikes.pts &lt;- as(hikes, &quot;SpatialPointsDataFrame&quot;) srtm.sp &lt;- as(srtm, &quot;SpatialPixelsDataFrame&quot;) hikes.pts$srtm &lt;- over(hikes.pts, srtm.sp) basemap &lt;- get_map(location=mu.bbox, zoom = 14, maptype=&quot;terrain&quot;) ## Warning: bounding box given to google - spatial extent only approximate. ## converting bounding box to center/zoom specification. (experimental) ## Source : https://maps.googleapis.com/maps/api/staticmap?center=44.852323,-68.625803&amp;zoom=14&amp;size=640x640&amp;scale=2&amp;maptype=terrain&amp;language=en-EN&amp;key=AIzaSyBPAwSY5x8vQqlnG-QwiCAWQW12U3CTLZY color.vals &lt;- srtm@data@values[1:length(hikes.pts)] ggmap(basemap) + geom_point(data=as.data.frame(hikes.pts), aes(x = coords.x1, y = coords.x2, color = color.vals)) + scale_color_gradient(low=&quot;green&quot;, high=&quot;red&quot;) + labs(color = &quot;Hiking trail elevation\\n(m above sea level)&quot;, xlab=&quot;Longitude&quot;, ylab=&quot;Latitude&quot;) ## Warning: Removed 483 rows containing missing values (geom_point). In the call to geom_point above, coords.x1 coords.x2 are the default names given to longitude and latitude, respectively, when sp coerces hikes to hikes.pts. These points represent the vertices along line segments. I create the vector color.vals that contains the values from srtm that I use in the map argument color. Normally, I would be able to simply use the argument color = srtm in the graph, but since there is a bug in the getData function I mentioned earlier, we need to do another workaround here. Overlay operations involving lines and polygons over polygons require the rgeos package which provides an interface to the Geometry Engine - Open Source (GEOS) C++ library for topology operations on geometries. We’ll leave it to you to explore these capabilities. 9.7.4 Spatial Aggregation We have seen aggregation operations before when using dplyr’s summarize function. The summarize function is particularly powerful when combined with group_by(), which can apply a function specified in summarize() to a variable partitioned using a grouping variable. The aggregate function in sp works in a similar manner, except groups are delineated by the spatial extent of a thematic variable. In fact, the work we did to create mu.bio using dplyr functions can be accomplished with aggregate(). Using aggregate() will, however, require a slightly different approach for joining the derived average biomass_mg_ha to the fortified mu. This is because the aggregate function will apply the user specified function to all variables in the input object, which, in our case, results in an NA for the linking variable mu_id as demonstrated below. mu.ag &lt;- aggregate(plots[,c(&quot;mu_id&quot;,&quot;biomass_mg_ha&quot;)], by=mu, FUN=mean) head(mu.ag@data, n=2) ## mu_id biomass_mg_ha ## 0 &lt;NA&gt; 49.85895 ## 1 &lt;NA&gt; 112.17077 With mu_id rendered useless, we do not have a variable that uniquely identifies each polygon for use in fortify’s region argument; hence no way to subsequently join the unfortified and fortified versions of mu.bio.ag. Here’s the work around. If the region is not specified, fortify() uses an internal unique polygon ID that is part of the sp data object and accessed via row.names()11 So, the trick is to add this unique polygon ID to the aggregate() output prior to calling fortify() as demonstrated below. mu.ag$id &lt;- row.names(mu.ag) mu.ag.f &lt;- fortify(mu.ag) ## Regions defined for each Polygons mu.ag.f &lt;- left_join(mu.ag.f, mu.ag@data) ## Joining, by = &quot;id&quot; ggmap(basemap) + geom_polygon(data=mu.ag.f, aes(x = long, y = lat, group=group, fill=biomass_mg_ha), size=0.2, color=&quot;orange&quot;) + scale_fill_gradient(low=&quot;white&quot;, high=&quot;darkblue&quot;, na.value=&quot;transparent&quot;) + labs(fill=&quot;Biomass (mg/ha)&quot;) The aggregate() function will work with all sp objects. For example let’s map the variance of pixel values in srtm.sp by management unit. Notice that aggregate() is happy to take a user-specified function for FUN. mu.srtm &lt;- aggregate(srtm.sp, by=mu, FUN=function(x){sqrt(var(x))}) mu.srtm$id &lt;- row.names(mu.srtm) mu.srtm.f &lt;- fortify(mu.srtm) ## Regions defined for each Polygons mu.srtm.f &lt;- left_join(mu.srtm.f, mu.srtm@data) ## Joining, by = &quot;id&quot; ggmap(basemap) + geom_polygon(data=mu.srtm.f, aes(x = long, y = lat, group=group, fill=srtm_23_04), size=0.2, color=&quot;orange&quot;) + scale_fill_gradient(low=&quot;green&quot;, high=&quot;red&quot;) + labs(fill = &quot;Elevation standard deviation\\n(m above sea level)&quot;, xlab=&quot;Longitude&quot;, ylab=&quot;Latitude&quot;) 9.8 Where to go from here This chapter just scratches the surface of R’s spatial data manipulation and visualization capabilities. The basic ideas we presented here should allow you to take a deeper look into sp, rgdal, rgeos, ggmap, leaflet, and a myriad of other excellent user-contributed R spatial data packages. A good place to start is with Edzer Pebesma’s excellent vignette on the use of the map overlay and spatial aggregation, available here, as well as Applied Spatial Data Analysis with R by . References "]
]
